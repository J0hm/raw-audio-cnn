~90% accuracy reached by epoch 10 on full VGG16 spec, 36,545,955 params. 
Seems to be plateau around 10-11. Scheduler may fix that, impossible to test without faster machine.

TODO: check if weights increase accuracy. It does solve the problem of some labels never being predicted, but it seems like it converges or plateaus slower. Needs more testing on better hardware
TODO: seperate vgg16_test.py into multiple files (dataloader/preprocess, model, train/test)
TODO: test with similar kernels/strides/padding as M11/M18

n_channel=64: 36,545,955 params, 77% first epoch accuracy
n_channel=32: 9,182,947 params, 63: first epoch 
n_channel=8: 591,397 params, 61% first epoch accuracy
n_channel=4: 154,675 params, 45% first epoch accuracy
n_channel=2: 41,347 params, 32% first epoch accuracy
n_channel=1: 11,814 params, 19% first epoch accuracy. 42% epoch 5 accuracy.

n_channel=1, 5 epochs with weights: 48%, 38%, 19%, 41%
n_channel=1, 5 epochs without weights: 42%, 32% 

n_channel=1, 5 epochs, no weights, dropout on: Many labels zeroed
n_channel=1, 5 epochs, weights, dropout: only 3 layers zeroed on first epoch, very low accuracy

Dropout on the FC layers also needs more testing

n_channel=32, weights=true, dropout on, patience=4: hovers around 92-93% accuracy until epoch 35, at which plateau was detected and LR reduced to 0.0001, accuracy quickly increased to 95%+.
    Loss 0.05 to 0.01 in few epochs. Estimated 100-120 epochs for a fully trained net. TODO: graph average loss
    Stopped after 60 epochs, where the LR was close to being decreased again. Stayed at 95% accuracy for 20+ epochs but the loss very slowly declined (reaching 0.008 avg loss at 60 epochs)
    Worth looking into n_channel=64 still: more compute power will be required, but it may be worth it. Network will be too large to deploy, probably even at n_channel=32 or 16, so I will look into pruning.



